# ML Машинное обучение — сессионный проект
1. Описание проекта

Проект реализован в рамках курса «Машинное обучение».
Цель: применить методы линейной и логистической регрессии, провести классификацию, оценить метрики моделей и создать интерактивный интерфейс для демонстрации работы.

Датасет: Wine Quality (White Wine)
Источник: UCI Machine Learning Repository
Описание полей: 11 физических и химических характеристик вина (fixed acidity, volatile acidity, citric acid, …) + целевая переменная quality.

2. Структура проекта

notebook.ipynb — основной ноутбук с кодом и визуализациями.

winequality-white.csv — датасет.

requirements.txt — зависимости.

README.md — инструкция по проекту.

В ноутбуке реализованы задачи:

Линейная регрессия (с нуля)

Градиентный спуск (batch) для обучения.

Вывод MSE, график потерь по эпохам, влияние learning rate.

Scatter plot данных с линией регрессии и доверительным интервалом.

Логистическая регрессия (с нуля)

Реализация сигмоиды, функции лог-потерь.

Обучение градиентным спуском (опционально с L2-регуляризацией).

Классификация (два подхода)

Бинарная классификация: логистическая регрессия + решающее дерево.

Метрики: accuracy, precision, recall, F1-score, ROC AUC, confusion matrix.

Эксперименты и метрики

Изменение learning rate, количества эпох, размера batch.

Сравнение качества моделей, анализ влияния признаков и переобучения.

Интерактивный интерфейс (widgets)

Настройка параметров обучения: learning rate, epochs, batch size.

Выбор модели и визуализация графиков потерь и метрик.

3. Инструкция по запуску

Скопировать репозиторий на локальный компьютер или открыть в Google Colab:

git clone <URL_репозитория>

или открыть .ipynb напрямую через Colab.

Установить зависимости:

pip install -r requirements.txt

Запустить notebook.ipynb и выполнить все ячейки последовательно.

4. Зависимости (requirements.txt)
numpy
pandas
matplotlib
scikit-learn
ipywidgets

Дополнительно можно использовать seaborn для визуализации.

5. Примечания

Все модели линейной и логистической регрессии реализованы вручную с использованием numpy.

Для второго классификатора (Decision Tree) используется scikit-learn.

Интерактивные виджеты реализованы через ipywidgets и полностью совместимы с Colab.

Датасет публичный, указан источник и описание полей.
